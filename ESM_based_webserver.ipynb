{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eOgwG39J15b"
   },
   "source": [
    "### load CleanLab processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iQjLpn9zV53L"
   },
   "outputs": [],
   "source": [
    "# load numpy array from csv file\n",
    "from numpy import loadtxt\n",
    "import numpy as np\n",
    "# load array\n",
    "X_new = loadtxt('X_Cleaned.csv', delimiter=',')\n",
    "y_new = loadtxt('y_Cleaned.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vnRH5gaJCHF",
    "outputId": "ca252ba1-4026-46ce-a0e6-1a2dc30291ac"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1020, 320)\n",
      "(1020,)\n",
      "401\n",
      "619\n"
     ]
    }
   ],
   "source": [
    "print(X_new.shape)\n",
    "print(y_new.shape)\n",
    "print(np.count_nonzero(y_new==0))\n",
    "print(np.count_nonzero(y_new==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4Ru7iocM6aE"
   },
   "source": [
    "### save the best performance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AQbu1XxtNFUG"
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### logistic regression saving"
   ],
   "metadata": {
    "id": "nU1vP1G5snT7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ah-bSWvcM-86"
   },
   "outputs": [],
   "source": [
    "# logistic regression for final test \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# result collection list\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=i)\n",
    "    # clf = LogisticRegression(penalty= 'none', C=i, max_iter = 2000)\n",
    "    clf = LogisticRegression(C=2000, max_iter=5000)\n",
    "    clf.fit(X_train_whole,y_train_whole)# fitting model \n",
    "    y_pred = clf.predict(X_ind_test)    # predict results\n",
    "    y_true = y_ind_test                 # asign values for confusiong matrix calculation\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    \n",
    "print(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\n",
    "# print(round(mean(AUC_collecton),3),'±',round(stdev(AUC_collecton),3))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "BACC_collecton"
   ],
   "metadata": {
    "id": "GbDy9Eemq_Xp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# we choose the performance around the average BACC random_state = 0"
   ],
   "metadata": {
    "id": "RmS-i-tIrFML"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# dataset splitting\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=1)\n",
    "# clf = LogisticRegression(penalty= 'none', C=i, max_iter = 2000)\n",
    "clf = LogisticRegression(C=2000, max_iter=5000)\n",
    "clf.fit(X_train_whole,y_train_whole)# fitting model \n",
    "y_pred = clf.predict(X_ind_test)    # predict results\n",
    "y_true = y_ind_test                 # asign values for confusiong matrix calculation\n",
    "TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "# Sn_collecton.append\n",
    "print('Sn_collecton', (TP/(TP+FN)))\n",
    "# Sp_collecton.append\n",
    "print('Sp_collecton', (TN/(TN+FP)))\n",
    "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "print('MCC_collection',MCC)\n",
    "# BACC\n",
    "print('BACC', (0.5*TP/(TP+FN)+0.5*TN/(TN+FP)))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzteRHCcrccW",
    "outputId": "1593d5d2-b17c-4ec1-d2d7-217df3bf0011"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sn_collecton 0.9054054054054054\n",
      "Sp_collecton 0.8769230769230769\n",
      "MCC_collection 0.7656758452182151\n",
      "BASCC 0.8911642411642411\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# save the logistic regression model\n",
    "import pickle\n",
    "pickle.dump(clf,open('LR.pkl','wb'))\n",
    "model_LR=pickle.load(open('LR.pkl','rb'))\n"
   ],
   "metadata": {
    "id": "HBKB5hItr4MU"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### MLP saving"
   ],
   "metadata": {
    "id": "qd3wjONqsqaT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# MLP one layer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# result collection list\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=i)\n",
    "    clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(1280, 32), max_iter=3000, n_iter_no_change=40) \n",
    "    clf.fit(X_train_whole,y_train_whole)# fitting model \n",
    "    y_pred = clf.predict(X_ind_test)    # predict results\n",
    "    y_true = y_ind_test                 # asign values for confusiong matrix calculation\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    \n",
    "print(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\n",
    "# print(round(mean(AUC_collecton),3),'±',round(stdev(AUC_collecton),3))\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZ09ACC_sd5U",
    "outputId": "eda716c5-8351-49a9-ef9e-465f412f32c0"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.86 ± 0.03\n",
      "0.832 ± 0.056\n",
      "0.889 ± 0.041\n",
      "0.718 ± 0.061\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "BACC_collecton"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGW0KPFetLPJ",
    "outputId": "7278c89a-f43c-4f3b-e11f-6b27534aed85"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.8708567192629462,\n",
       " 0.8831475852752448,\n",
       " 0.8941231831015372,\n",
       " 0.8830379746835443,\n",
       " 0.8858363858363858,\n",
       " 0.8431451612903226,\n",
       " 0.8309755378720896,\n",
       " 0.849404761904762,\n",
       " 0.7970983797521973,\n",
       " 0.8670478170478171]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# dataset splitting\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=9)\n",
    "# clf = LogisticRegression(penalty= 'none', C=i, max_iter = 2000)\n",
    "clf = LogisticRegression(C=2000, max_iter=5000)\n",
    "clf.fit(X_train_whole,y_train_whole)# fitting model \n",
    "y_pred = clf.predict(X_ind_test)    # predict results\n",
    "y_true = y_ind_test                 # asign values for confusiong matrix calculation\n",
    "TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "# Sn_collecton.append\n",
    "print('Sn_collecton', (TP/(TP+FN)))\n",
    "# Sp_collecton.append\n",
    "print('Sp_collecton', (TN/(TN+FP)))\n",
    "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "print('MCC_collection',MCC)\n",
    "# BACC\n",
    "print('BACC', (0.5*TP/(TP+FN)+0.5*TN/(TN+FP)))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFqszjTgtKkz",
    "outputId": "0ad2cdbe-5ab9-4148-85ea-b60b0df6aa49"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sn_collecton 0.8571428571428571\n",
      "Sp_collecton 0.8818897637795275\n",
      "MCC_collection 0.7321764677633454\n",
      "BACC 0.8695163104611923\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# save the logistic regression model\n",
    "import pickle\n",
    "pickle.dump(clf,open('MLP.pkl','wb'))\n",
    "model_LR=pickle.load(open('MLP.pkl','rb'))\n"
   ],
   "metadata": {
    "id": "jwYXaT1Rs00r"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM model saving"
   ],
   "metadata": {
    "id": "GWwtKN3OsxYJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "# result collection list\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=i)\n",
    "    clf = SVC(C=300, degree=5, kernel='linear')\n",
    "    clf.fit(X_train_whole,y_train_whole)# fitting model \n",
    "    y_pred = clf.predict(X_ind_test)    # predict results\n",
    "    y_true = y_ind_test                 # asign values for confusiong matrix calculation\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    \n",
    "print(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\n",
    "# print(round(mean(AUC_collecton),3),'±',round(stdev(AUC_collecton),3))\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fg9IueBCsg2K",
    "outputId": "84deccc3-2f5c-47f2-de08-2df4a6aa8cd7"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.871 ± 0.029\n",
      "0.833 ± 0.046\n",
      "0.908 ± 0.03\n",
      "0.744 ± 0.055\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "BACC_collecton"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKjGa5j5uJkq",
    "outputId": "70180cec-09a7-4ed9-bc07-c9acaf1adb09"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.8942028985507247,\n",
       " 0.874108527131783,\n",
       " 0.8553113553113554,\n",
       " 0.8830329153605017,\n",
       " 0.8881520778072503,\n",
       " 0.9168696388859472,\n",
       " 0.8109342764515178,\n",
       " 0.8492602958816473,\n",
       " 0.8714896214896215,\n",
       " 0.8635531135531136]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# dataset splitting\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=9)\n",
    "# clf = LogisticRegression(penalty= 'none', C=i, max_iter = 2000)\n",
    "clf = SVC(C=300, degree=5, kernel='linear')\n",
    "clf.fit(X_train_whole,y_train_whole)# fitting model \n",
    "y_pred = clf.predict(X_ind_test)    # predict results\n",
    "y_true = y_ind_test                 # asign values for confusiong matrix calculation\n",
    "TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "# Sn_collecton.append\n",
    "print('Sn_collecton', (TP/(TP+FN)))\n",
    "# Sp_collecton.append\n",
    "print('Sp_collecton', (TN/(TN+FP)))\n",
    "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "print('MCC_collection',MCC)\n",
    "# BACC\n",
    "print('BACC', (0.5*TP/(TP+FN)+0.5*TN/(TN+FP)))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SM2WbvSHuK8f",
    "outputId": "ed8abf55-68dd-47d9-e1d8-5a3eff35cca4"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sn_collecton 0.8461538461538461\n",
      "Sp_collecton 0.8809523809523809\n",
      "MCC_collection 0.7221632314801458\n",
      "BACC 0.8635531135531136\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# save the logistic regression model\n",
    "import pickle\n",
    "pickle.dump(clf,open('SVM.pkl','wb'))\n",
    "model_LR=pickle.load(open('SVM.pkl','rb'))\n"
   ],
   "metadata": {
    "id": "Nzzgb4Lqs1V8"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### webserver"
   ],
   "metadata": {
    "id": "HrISxAnqvU-_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install fair-esm"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0EQvXFAxusw",
    "outputId": "b8b76798-508e-4b52-f73e-36b8fa9e5db2"
   },
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting fair-esm\n",
      "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m93.1/93.1 KB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: fair-esm\n",
      "Successfully installed fair-esm-2.0.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torch"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_Q6qC5nxyww",
    "outputId": "4ea0986b-90d6-4f2a-9b5a-0ba9260a9a1c"
   },
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install flask"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpOjjTEkx2TI",
    "outputId": "b2fcc8f0-a533-4431-c736-60caf8c6cfbf"
   },
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.8/dist-packages (1.1.4)\n",
      "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from flask) (1.1.0)\n",
      "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from flask) (7.1.2)\n",
      "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from flask) (1.0.1)\n",
      "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from flask) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->flask) (2.0.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from flask import Flask,request, url_for, redirect, render_template\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# embeddings function\n",
    "def esm_embeddings(peptide_sequence_list: list):\n",
    "    # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long,\n",
    "    #         or you have too many sequences for transformation in a single converting,\n",
    "    #         you conputer might automatically kill the job.\n",
    "    # return a panda.dataframe\n",
    "    import torch\n",
    "    import pandas as pd\n",
    "    import esm\n",
    "    import collections\n",
    "    # load the model\n",
    "    # NOTICE: if the model was not downloaded in your local environment, it will automatically download it.\n",
    "    model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "    # load the peptide sequence list into the bach_converter\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "    ## batch tokens are the embedding results of the whole data set\n",
    "\n",
    "    # Extract per-residue representations (on CPU)\n",
    "    with torch.no_grad():\n",
    "        # Here we export the last layer of the EMS model output as the representation of the peptides\n",
    "       # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
    "        results = model(batch_tokens, repr_layers=[6], return_contacts=True)\n",
    "    token_representations = results[\"representations\"][6]\n",
    "\n",
    "    # Generate per-sequence representations via averaging\n",
    "    # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "    sequence_representations = []\n",
    "    for i, tokens_len in enumerate(batch_lens):\n",
    "        sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
    "    # save dataset\n",
    "    # sequence_representations is a list and each element is a tensor\n",
    "    embeddings_results = collections.defaultdict(list)\n",
    "    for i in range(len(sequence_representations)):\n",
    "        # tensor can be transformed as numpy sequence_representations[0].numpy() or  sequence_representations[0].to_list\n",
    "        each_seq_rep = sequence_representations[i].tolist()\n",
    "        for each_element in each_seq_rep:\n",
    "            embeddings_results[i].append(each_element)\n",
    "    embeddings_results = pd.DataFrame(embeddings_results).T\n",
    "    return embeddings_results\n",
    "\n",
    "# collect the output\n",
    "def assign_activity(predicted_class):\n",
    "    import collections\n",
    "    out_put = []\n",
    "    for i in range(len(predicted_class)):\n",
    "        if predicted_class[i] == 0:\n",
    "            #out_put[int_features[i]].append(1)\n",
    "            out_put.append('active')\n",
    "        else:\n",
    "            #out_put[int_features[i]].append(2)\n",
    "            out_put.append('non-active')\n",
    "    return out_put\n",
    "\n",
    "def model_selection(num: str):\n",
    "    model = ''\n",
    "    if num == '1':\n",
    "        model = 'LR.pkl'\n",
    "    elif num == '2':\n",
    "        model = 'SVM.pkl'\n",
    "    elif num == '3':\n",
    "        model = 'MLP.pkl'\n",
    "    return model\n",
    "\n",
    "\n",
    "# create an app object using the Flask class\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # 每一个网页上的 输入的框，是一个单独的x，下面这个就是吧这个单独的信息变成一个list，每一个单独的就是一个str （也可以吧x变成int 如果想要的话）\n",
    "    # int_features  = [str(x) for x in request.form.values()] # this command basically use extract all the input into a list\n",
    "    #final_features = [np.array(int_features)]\n",
    "    int_features  = [str(x) for x in request.form.values()]\n",
    "    # we have two input in the website, one is the model type and other is the peptide sequences\n",
    "    \n",
    "    # choose scaler and model\n",
    "    # name = int_features[0]\n",
    "    model_name = model_selection(int_features[0])\n",
    "\n",
    "    model=pickle.load(open(model_name,'rb'))\n",
    "\n",
    "    sequence_list=int_features[1].split(',')  # 因为这个list里又两个element我们需要第二个，所以我只需要把吧这个拿出来，然后split\n",
    "    # 另外需要注意，这个地方，网页上输入的时候必须要是AAA,CCC,SAS, 这个格式，不同的sequence的区分只能使用逗号，其他的都不可以\n",
    "    peptide_sequence_list = []\n",
    "    for seq in sequence_list:\n",
    "        format_seq = [seq, seq]  # the setting is just following the input format setting in ESM model, [name,sequence]\n",
    "        tuple_sequence = tuple(format_seq)\n",
    "        peptide_sequence_list.append(tuple_sequence)  # build a summarize list variable including all the sequence information\n",
    "\n",
    "    embeddings_results = esm_embeddings(peptide_sequence_list) #conduct the embedding\n",
    "\n",
    "    # prediction\n",
    "    predicted_class = model.predict(embeddings_results)\n",
    "    predicted_class = assign_activity(predicted_class) # transform results (0 and 1) into 'active' and 'non-active'\n",
    "\n",
    "    return render_template('index.html',prediction_text=\"Prediction results of input sequences {}\".format(predicted_class))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIN2rAr2vXKM",
    "outputId": "715b034d-456e-4006-dc68-abc66f785798"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.chdir('/Users/zhenjiaodu/no_icloud/1. ksu-in class/CIS 730 introduction to artifical intelligence/term project/BERT_4_ACE/LM4ACE webserver/app.py')\n"
   ],
   "metadata": {
    "id": "Fsfv4-5EwMzZ"
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Address already in use\n",
      "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
      "On macOS, try disabling the 'AirPlay Receiver' service from System Preferences -> Sharing.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/zhenjiaodu/opt/anaconda3/lib/python3.8/site-packages/werkzeug/serving.py\", line 911, in prepare_socket\n",
      "    s.bind(server_address)\n",
      "OSError: [Errno 48] Address already in use\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zhenjiaodu/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/jn/46mlt8753tq08psvz71pkvnr0000gn/T/ipykernel_57492/2791326728.py\", line 113, in <module>\n",
      "    app.run()\n",
      "  File \"/Users/zhenjiaodu/opt/anaconda3/lib/python3.8/site-packages/flask/app.py\", line 1188, in run\n",
      "    run_simple(t.cast(str, host), port, self, **options)\n",
      "  File \"/Users/zhenjiaodu/opt/anaconda3/lib/python3.8/site-packages/werkzeug/serving.py\", line 1062, in run_simple\n",
      "    s = prepare_socket(hostname, port)\n",
      "  File \"/Users/zhenjiaodu/opt/anaconda3/lib/python3.8/site-packages/werkzeug/serving.py\", line 930, in prepare_socket\n",
      "    sys.exit(1)\n",
      "SystemExit: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zhenjiaodu/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/zhenjiaodu/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/zhenjiaodu/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/zhenjiaodu/opt/anaconda3/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/werkzeug/serving.py\u001B[0m in \u001B[0;36mprepare_socket\u001B[0;34m(hostname, port)\u001B[0m\n\u001B[1;32m    910\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 911\u001B[0;31m         \u001B[0ms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mserver_address\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    912\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOSError\u001B[0m: [Errno 48] Address already in use",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mSystemExit\u001B[0m                                Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m/var/folders/jn/46mlt8753tq08psvz71pkvnr0000gn/T/ipykernel_57492/2791326728.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'__main__'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 113\u001B[0;31m     \u001B[0mapp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/flask/app.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, host, port, debug, load_dotenv, **options)\u001B[0m\n\u001B[1;32m   1187\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1188\u001B[0;31m             \u001B[0mrun_simple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhost\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mport\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1189\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/werkzeug/serving.py\u001B[0m in \u001B[0;36mrun_simple\u001B[0;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, exclude_patterns, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001B[0m\n\u001B[1;32m   1061\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_running_from_reloader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1062\u001B[0;31m         \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprepare_socket\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhostname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mport\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1063\u001B[0m         \u001B[0mfd\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfileno\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/werkzeug/serving.py\u001B[0m in \u001B[0;36mprepare_socket\u001B[0;34m(hostname, port)\u001B[0m\n\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 930\u001B[0;31m         \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    931\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mSystemExit\u001B[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2052\u001B[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001B[1;32m   2053\u001B[0m                            'the full traceback.\\n']\n\u001B[0;32m-> 2054\u001B[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001B[0m\u001B[1;32m   2055\u001B[0m                                                                      value))\n\u001B[1;32m   2056\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mget_exception_only\u001B[0;34m(self, etype, value)\u001B[0m\n\u001B[1;32m    752\u001B[0m         \u001B[0mvalue\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0mexception\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    753\u001B[0m         \"\"\"\n\u001B[0;32m--> 754\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mListTB\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstructured_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    755\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    756\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mshow_exception_only\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, context)\u001B[0m\n\u001B[1;32m    627\u001B[0m             \u001B[0mchained_exceptions_tb_offset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    628\u001B[0m             out_list = (\n\u001B[0;32m--> 629\u001B[0;31m                 self.structured_traceback(\n\u001B[0m\u001B[1;32m    630\u001B[0m                     \u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0metb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchained_exc_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    631\u001B[0m                     chained_exceptions_tb_offset, context)\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1365\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1367\u001B[0;31m         return FormattedTB.structured_traceback(\n\u001B[0m\u001B[1;32m   1368\u001B[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[1;32m   1369\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1265\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose_modes\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1266\u001B[0m             \u001B[0;31m# Verbose modes need a full traceback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1267\u001B[0;31m             return VerboseTB.structured_traceback(\n\u001B[0m\u001B[1;32m   1268\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1269\u001B[0m             )\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1122\u001B[0m         \u001B[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1124\u001B[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[0m\u001B[1;32m   1125\u001B[0m                                                                tb_offset)\n\u001B[1;32m   1126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1081\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1082\u001B[0;31m         \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1083\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1084\u001B[0m         \u001B[0mframes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[0;34m(etype, value, records)\u001B[0m\n\u001B[1;32m    380\u001B[0m     \u001B[0;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    381\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 382\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    383\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    384\u001B[0m     \u001B[0;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "95NTckuFZZzm",
    "m91cA0H5w_eY",
    "RddxugbsdR1Y",
    "9EzJGXsk1w-Z",
    "dN8Xh24_RHtp",
    "2eOgwG39J15b",
    "EzMyShvqxxAy",
    "lDxnvWKb1rTP",
    "5P1fK2FJApwf",
    "YjMK3qEHAvLV",
    "Cp1Han6zB1vU",
    "qoJpjw-uCihR",
    "XUm2yu6cCqi7",
    "pIZ278ZDOwmA",
    "f4Ru7iocM6aE",
    "XmntS7leeBR3",
    "H7i852E3TUgi",
    "hOABwh18TfeX",
    "U3Fagh9Iw83q"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
